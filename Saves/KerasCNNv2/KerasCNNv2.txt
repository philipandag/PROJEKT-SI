Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 24, 24, 32)        832       
                                                                 
 conv2d_1 (Conv2D)           (None, 20, 20, 32)        25600     
                                                                 
 batch_normalization (BatchN  (None, 20, 20, 32)       128       
 ormalization)                                                   
                                                                 
 activation (Activation)     (None, 20, 20, 32)        0         
                                                                 
 max_pooling2d (MaxPooling2D  (None, 10, 10, 32)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 10, 10, 32)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 8, 8, 64)          18496     
                                                                 
 conv2d_3 (Conv2D)           (None, 6, 6, 64)          36864     
                                                                 
 batch_normalization_1 (Batc  (None, 6, 6, 64)         256       
 hNormalization)                                                 
                                                                 
 activation_1 (Activation)   (None, 6, 6, 64)          0         
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 3, 3, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 3, 3, 64)          0         
                                                                 
 flatten (Flatten)           (None, 576)               0         
                                                                 
 dense (Dense)               (None, 256)               147456    
                                                                 
 batch_normalization_2 (Batc  (None, 256)              1024      
 hNormalization)                                                 
                                                                 
 activation_2 (Activation)   (None, 256)               0         
                                                                 
 dense_1 (Dense)             (None, 128)               32768     
                                                                 
 batch_normalization_3 (Batc  (None, 128)              512       
 hNormalization)                                                 
                                                                 
 activation_3 (Activation)   (None, 128)               0         
                                                                 
 dense_2 (Dense)             (None, 84)                10752     
                                                                 
 batch_normalization_4 (Batc  (None, 84)               336       
 hNormalization)                                                 
                                                                 
 activation_4 (Activation)   (None, 84)                0         
                                                                 
 dropout_2 (Dropout)         (None, 84)                0         
                                                                 
 dense_3 (Dense)             (None, 10)                850       
                                                                 
=================================================================
Total params: 275,874
Trainable params: 274,746
Non-trainable params: 1,128
_________________________________________________________________

MNIST-784:

Walidacja...
438/438 [==============================] - 2s 4ms/step - loss: 0.0357 - accuracy: 0.9924
Wynik:  0.9923571348190308

Class  0 TP:  1339 FP:  4 FN:  4 TN:  12653
        Precision:  0.9970215934475056
        Recall:  0.9970215934475056
        F1:  0.9970215934475056
        Accuracy:  0.9994285714285714

Class  1 TP:  1599 FP:  12 FN:  1 TN:  12388
        Precision:  0.9925512104283054
        Recall:  0.999375
        F1:  0.9959514170040487
        Accuracy:  0.9990714285714286

Class  2 TP:  1367 FP:  14 FN:  13 TN:  12606
        Precision:  0.9898624185372918
        Recall:  0.9905797101449275
        F1:  0.990220934444042
        Accuracy:  0.9980714285714286

Class  3 TP:  1416 FP:  8 FN:  17 TN:  12559
        Precision:  0.9943820224719101
        Recall:  0.9881367759944173
        F1:  0.9912495624781238
        Accuracy:  0.9982142857142857

Class  4 TP:  1289 FP:  13 FN:  6 TN:  12692
        Precision:  0.9900153609831029
        Recall:  0.9953667953667954
        F1:  0.99268386599923
        Accuracy:  0.9986428571428572

Class  5 TP:  1256 FP:  9 FN:  17 TN:  12718
        Precision:  0.9928853754940712
        Recall:  0.9866457187745483
        F1:  0.9897557131599685
        Accuracy:  0.9981428571428571

Class  6 TP:  1391 FP:  9 FN:  5 TN:  12595
        Precision:  0.9935714285714285
        Recall:  0.9964183381088825
        F1:  0.9949928469241773
        Accuracy:  0.999

Class  7 TP:  1490 FP:  11 FN:  13 TN:  12486
        Precision:  0.9926715522984677
        Recall:  0.9913506320691949
        F1:  0.9920106524633822
        Accuracy:  0.9982857142857143

Class  8 TP:  1343 FP:  12 FN:  14 TN:  12631
        Precision:  0.9911439114391144
        Recall:  0.9896831245394252
        F1:  0.9904129793510325
        Accuracy:  0.9981428571428571

Class  9 TP:  1403 FP:  15 FN:  17 TN:  12565
        Precision:  0.9894217207334274
        Recall:  0.9880281690140845
        F1:  0.9887244538407329
        Accuracy:  0.9977142857142857

fashion-MNIST:

Walidacja...
438/438 [==============================] - 2s 4ms/step - loss: 0.2610 - accuracy: 0.9118
Wynik:  0.9117857217788696

Class  0 TP:  1197 FP:  186 FN:  197 TN:  12420
        Precision:  0.8655097613882863
        Recall:  0.8586800573888091
        F1:  0.8620813827871804
        Accuracy:  0.9726428571428571

Class  1 TP:  1376 FP:  13 FN:  26 TN:  12585
        Precision:  0.9906407487401008
        Recall:  0.9814550641940085
        F1:  0.9860265137943389
        Accuracy:  0.9972142857142857

Class  2 TP:  1208 FP:  175 FN:  199 TN:  12418
        Precision:  0.8734634851771511
        Recall:  0.8585643212508884
        F1:  0.8659498207885306
        Accuracy:  0.9732857142857143

Class  3 TP:  1344 FP:  149 FN:  105 TN:  12402
        Precision:  0.9002009377093101
        Recall:  0.927536231884058
        F1:  0.9136641740312712
        Accuracy:  0.9818571428571429

Class  4 TP:  1156 FP:  201 FN:  201 TN:  12442
        Precision:  0.8518791451731761
        Recall:  0.8518791451731761
        F1:  0.8518791451731761
        Accuracy:  0.9712857142857143

Class  5 TP:  1400 FP:  20 FN:  49 TN:  12531
        Precision:  0.9859154929577465
        Recall:  0.966183574879227
        F1:  0.9759498082955733
        Accuracy:  0.9950714285714286

Class  6 TP:  1056 FP:  352 FN:  351 TN:  12241
        Precision:  0.75
        Recall:  0.7505330490405118
        F1:  0.750266429840142
        Accuracy:  0.9497857142857142

Class  7 TP:  1336 FP:  82 FN:  23 TN:  12559
        Precision:  0.9421720733427362
        Recall:  0.9830757910228108
        F1:  0.9621894130356499
        Accuracy:  0.9925

Class  8 TP:  1310 FP:  31 FN:  32 TN:  12627
        Precision:  0.976882923191648
        Recall:  0.9761549925484352
        F1:  0.9765188222139396
        Accuracy:  0.9955

Class  9 TP:  1382 FP:  26 FN:  52 TN:  12540
        Precision:  0.9815340909090909
        Recall:  0.9637377963737797
        F1:  0.9725545390570021
        Accuracy:  0.9944285714285714